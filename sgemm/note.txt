

为了方便处理带batch维度的tensor，在linear中一般是x乘上w

cublas输入都是列主序存储，如果要计算a @ b，则实际调用gemm传入b和a

cutlass支持shape和stride, 不支持step, 因为step可以吸收到stride中

输入A, B, C, alpha, beta, M, N, K, 其中A是M*K, B是K*N, C是M*N, ABC都使用列主序存储, 计算C = alpha * A @ B + beta * C

- native: grid(M / 16, N / 16) block(16, 16) 每个thread计算C中一个位置的最终值
- smem_cache: grid(M / 16, N / 16) block(16, 16) 每个block维护一个在smem上的tile, 减少gmem加载次数
- rmem_cache: grid(M / 256, N / 256) block(4, 4)
- mem_coalesce:
- vector_memory_access
- double buffer
- wmma
- mma
- cutlass
- triton
- tilelang

- 什么参数应该设置为模板参数
- 什么时候应该使用sync
- rmem cache是如何实现的
- 实际上gemm应该考虑更多细节，比如当shape不能被tile size整除，比如tile size应该是二维的


## 调试工具
- Compute Sanitizer
- cuda gdb
- printf

## 传入行主序输入，但是gemm处理列主序

torch 创建tensor默认行主序

tensor转置不生成新tensor，只改变view，但是is_contiguous()返回False, 因为这里的contiguous指的按行访问时连续的


